from langchain_core.messages import HumanMessage, AIMessage
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from prompt.feedback import get_feedback
from prompt.summary import get_summary_prompt
from prompt.question import generate_question_with_rag
from config.parameters import get_llm
from rag.loader import load_and_split_file
from rag.vector_store import save_to_faiss

import streamlit as st

llm = get_llm()


def init_session():
    st.session_state.stage = "select_topic"
    st.session_state.uploaded_file_name = None
    st.session_state.selected_topics = []
    st.session_state.messages = []
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.feedbacks = []

    # st.session_state.memory = ConversationBufferMemory(
    #     memory_key="chat_history",
    #     return_messages=True,
    # )
    st.session_state.memory = ChatMessageHistory()


def render_ui(page_title="ë‚˜ì˜ ë©´ì ‘ê´€"):
    st.set_page_config(page_title=page_title)
    st.title(page_title)

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        init_session()

    # ë¬¸ì„œ ì—…ë¡œë“œ (RAG)
    st.sidebar.header("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.sidebar.file_uploader(
        "ì´ë ¥ì„œ, í¬íŠ¸í´ë¦¬ì˜¤ ë“± ì§ˆë¬¸ë°›ê³  ì‹¶ì€ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. (pdf, txt, md)",
        type=["pdf", "txt", "md"]
    )
    if uploaded_file and uploaded_file.name != st.session_state.get("uploaded_file_name"):
        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            chunks = load_and_split_file(uploaded_file)
            save_to_faiss(chunks)
            st.session_state.uploaded_file_name = uploaded_file.name
            st.sidebar.success(f"{len(chunks)}ê°œì˜ ë¬¸ì„œ ì²­í¬ê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        init_session()
        st.rerun()

    # ê¸°ìˆ  ì„ íƒ ë‹¨ê³„
    if st.session_state.stage == "select_topic":
        tech_input = st.text_input("ì—°ìŠµí•˜ê³  ì‹¶ì€ ê¸°ìˆ ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: Java, SpringBoot, MySQL ë“±)")
        if st.button("ì‹œì‘í•˜ê¸°") and tech_input.strip():
            st.session_state.selected_topics = [t.strip() for t in tech_input.split(",") if t.strip()]
            st.session_state.stage = "ask"
            st.rerun()

    # ì§ˆë¬¸ ìƒì„± ë‹¨ê³„
    elif st.session_state.stage == "ask":
        history = st.session_state.memory
        question_prompt = generate_question_with_rag(st.session_state.selected_topics, history)
        
        print("=====",history)
        st.session_state.questions.append(question_prompt)
        st.session_state.messages.append(AIMessage(content=question_prompt))
        st.session_state.stage = "wait_answer"
        st.rerun()

    # ê¸°ì¡´ ë©”ì‹œì§€ ë Œë”ë§
    if st.session_state.messages:
        for message in st.session_state.messages:
            role = "user" if isinstance(message, HumanMessage) else "assistant"
            with st.chat_message(role):
                st.markdown(message.content)

    # ì‚¬ìš©ì ì…ë ¥ ë° í”¼ë“œë°± ì²˜ë¦¬
    if st.session_state.stage == "wait_answer":
        user_input = st.chat_input("ì§ˆë¬¸ì— ë‹µë³€í•´ë³´ì„¸ìš”.", key="user_input")
        if user_input:
            history = st.session_state.memory
            st.session_state.answers.append(user_input)
            st.session_state.messages.append(HumanMessage(content=user_input))
            feedback = get_feedback(user_input, history)
            st.session_state.feedbacks.append(feedback)
            st.session_state.messages.append(AIMessage(content=feedback))
            st.session_state.stage = "confirm_next"
            st.rerun()

    # ë‹¤ìŒ ì§ˆë¬¸ ì—¬ë¶€ ì„ íƒ
    elif st.session_state.stage == "confirm_next":
        st.markdown("ë‹¤ìŒ ì§ˆë¬¸ì„ ì´ì–´ì„œ ì§„í–‰í• ê¹Œìš”?")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("â¡ï¸ ë„¤, ë‹¤ìŒ ì§ˆë¬¸"):
                st.session_state.stage = "ask"
                st.rerun()
        with col2:
            if st.button("ğŸ›‘ ê·¸ë§Œí• ê²Œìš”"):
                st.session_state.stage = "summary"
                st.rerun()

    # ì „ì²´ ìš”ì•½
    elif st.session_state.stage == "summary":
        with st.spinner("ë‹¹ì‹ ì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
            qa_text = "\n\n".join(
                f"Q: {q}\nA: {a}\nFeedback: {f}"
                for q, a, f in zip(
                    st.session_state.questions,
                    st.session_state.answers,
                    st.session_state.feedbacks
                )
            )
            summary_prompt = get_summary_prompt().format(qa_history=qa_text)
            summary = llm.invoke(summary_prompt).content

            st.markdown("### ğŸ“‹ ë©´ì ‘ í”¼ë“œë°± ìš”ì•½")
            st.markdown(summary)


if __name__ == "__main__":
    render_ui()
