"""
Streamlit UI module for the interview chatbot application.

Contains functions to initialize session state, render UI components
based on the current workflow stage, and handle user interactions.

The UI flow covers:
- Document upload for retrieval-augmented generation (RAG)
- Technical topic selection
- Interview question generation and display
- User answer input and AI feedback generation
- Session summary display

All UI rendering functions accept:
- st: The Streamlit module, passed from the main application for flexibility.
- graph: The interview workflow StateGraph instance.
"""

from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_message_histories import ChatMessageHistory

from rag.loader import load_and_split_file
from rag.vector_store import save_to_faiss



def init_session(st):
    """
    Initialize all Streamlit session state variables for a fresh chatbot session.

    Args:
        st: The Streamlit module for session state management.
    """
    st.session_state.stage = "select_topic"
    st.session_state.uploaded_file_name = None
    st.session_state.selected_topics = []
    st.session_state.messages = []
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.feedbacks = []

    st.session_state.memory = ChatMessageHistory()
    st.session_state.graph_state = {
        "messages": [],
        "tech_keywords": "",
        "is_summary": False,
        "user_input": ""
    }
    st.session_state.graph_config = {"configurable": {"thread_id": "unique_session"}}


def render_document_upload(st):
    """
    Render the sidebar UI to upload documents (pdf, txt, md)
    and save their chunks to the FAISS vector store.

    Args:
        st: The Streamlit module for UI rendering.
    """
    st.sidebar.header("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.sidebar.file_uploader(
        "ì´ë ¥ì„œ, í¬íŠ¸í´ë¦¬ì˜¤ ë“± ì§ˆë¬¸ë°›ê³  ì‹¶ì€ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. (pdf, txt, md)",
        type=["pdf", "txt", "md"]
    )
    if uploaded_file and uploaded_file.name != st.session_state.get("uploaded_file_name"):
        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            chunks = load_and_split_file(uploaded_file)
            save_to_faiss(chunks)
            st.session_state.uploaded_file_name = uploaded_file.name
            st.sidebar.success(f"{len(chunks)}ê°œì˜ ë¬¸ì„œ ì²­í¬ê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()


def render_select_topic(st):
    """
    Render UI for the user to input and select technical topics to practice.

    Args:
        st: The Streamlit module for UI rendering.
    """
    tech_input = st.text_input("ì—°ìŠµí•˜ê³  ì‹¶ì€ ê¸°ìˆ ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: Java, SpringBoot, MySQL ë“±)")
    if st.button("ì‹œì‘í•˜ê¸°") and tech_input.strip():
        st.session_state.selected_topics = [t.strip() for t in tech_input.split(",") if t.strip()]
        st.session_state.stage = "ask"
        st.session_state.graph_state["tech_keywords"] = st.session_state.selected_topics
        st.rerun()


def render_ask(st, graph):
    """
    Generate an interview question by invoking the graph at the 'ask' step,
    display it, and update session state accordingly.

    Args:
        st: The Streamlit module for UI rendering.
        graph: The workflow StateGraph instance managing the interview process.
    """
    graph.update_state(values=st.session_state.graph_state, config=st.session_state.graph_config)
    question_prompt = graph.invoke(None,
                                   interrupt_after="ask",
                                   config=st.session_state.graph_config)
    st.session_state.graph_state = question_prompt
    question = question_prompt["messages"][-1]["content"]
    st.session_state.questions.append(question)
    st.session_state.messages.append(AIMessage(content=question))
    st.session_state.stage = "wait_answer"
    st.rerun()


def render_messages(st):
    """
    Render the chat messages (user and assistant) in the Streamlit chat UI.

    Args:
        st: The Streamlit module for UI rendering.
    """
    if st.session_state.messages:
        for message in st.session_state.messages:
            role = "user" if isinstance(message, HumanMessage) else "assistant"
            with st.chat_message(role):
                st.markdown(message.content)


def render_wait_answer(st, graph):
    """
    Display an input box for the user to answer the current question,
    send the answer to the graph for feedback generation, and update the session.

    Args:
        st: The Streamlit module for UI rendering.
        graph: The workflow StateGraph instance managing the interview process.
    """
    user_input = st.chat_input("ì§ˆë¬¸ì— ë‹µë³€í•´ë³´ì„¸ìš”.", key="user_input")
    if user_input:
        st.session_state.answers.append(user_input)
        st.session_state.messages.append(HumanMessage(content=user_input))
        st.session_state.graph_state["user_input"] = user_input
        graph.update_state(values=st.session_state.graph_state,
                           config=st.session_state.graph_config)
        response = graph.invoke(None, interrupt_after="feedback",
                                config=st.session_state.graph_config)
        st.session_state.graph_state = response
        feedback = response['messages'][-1]['content']
        st.session_state.feedbacks.append(feedback)
        st.session_state.messages.append(AIMessage(content=feedback))
        st.session_state.stage = "confirm_next"
        st.rerun()


def render_confirm_next(st):
    """
    Ask the user whether to continue with the next question or finish the session.

    Args:
        st: The Streamlit module for UI rendering.
    """
    st.markdown("ë‹¤ìŒ ì§ˆë¬¸ì„ ì´ì–´ì„œ ì§„í–‰í• ê¹Œìš”?")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("â¡ï¸ ë„¤, ë‹¤ìŒ ì§ˆë¬¸"):
            st.session_state.stage = "ask"
            st.rerun()
    with col2:
        if st.button("ğŸ›‘ ê·¸ë§Œí• ê²Œìš”"):
            st.session_state.stage = "summary"
            st.session_state.graph_state["is_summary"] = True
            st.rerun()


def render_summary(st, graph):
    """
    Generate and display a summary feedback based on the entire interview session.

    Args:
        st: The Streamlit module for UI rendering.
        graph: The workflow StateGraph instance managing the interview process.
    """
    with st.spinner("ë‹¹ì‹ ì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
        graph.update_state(values=st.session_state.graph_state,
                           config=st.session_state.graph_config)
        response = graph.invoke(None, config=st.session_state.graph_config)
        summary = response['messages'][-1]['content']
        st.markdown("### ğŸ“‹ ë©´ì ‘ í”¼ë“œë°± ìš”ì•½")
        st.markdown(summary)


def render_ui(st, graph, page_title="ë‚˜ì˜ ë©´ì ‘ê´€"):
    """
    Main function to render the entire Streamlit UI for the interview chatbot,
    routing UI rendering to the appropriate stage-specific functions.

    Args:
        st: The Streamlit module for UI rendering.
        graph: The workflow StateGraph instance managing the interview process.
        page_title (str): Title displayed on the Streamlit app page.
    """
    st.set_page_config(page_title=page_title)
    st.title(page_title)

    if "messages" not in st.session_state:
        init_session(st)

    render_document_upload(st)

    stage = st.session_state.stage

    if stage == "select_topic":
        render_select_topic(st)
    elif stage == "ask":
        render_ask(st, graph)
    elif stage == "wait_answer":
        render_messages(st)
        render_wait_answer(st, graph)
    elif stage == "confirm_next":
        render_messages(st)
        render_confirm_next(st)
    elif stage == "summary":
        render_summary(st, graph)
